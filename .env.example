# === Immagine Docker ===
# GPU: vllm/vllm-openai:v0.11.0 (prima versione con dots.ocr integrato)
VLLM_IMAGE=vllm/vllm-openai:v0.11.0
# CPU: decommentare per usare la versione CPU
# VLLM_CPU_IMAGE=public.ecr.aws/q9t5s3a7/vllm-cpu-release-repo:latest

# === Modello OCR ===
# Modello standard (~3.5GB, richiede ~10GB VRAM)
OCR_MODEL=rednote-hilab/dots.ocr
# Modello quantizzato AWQ 4-bit (~0.8GB, per GPU con poca VRAM come 8-12GB)
# OCR_MODEL=sugam24/dots-ocr-awq-4bit

# === Rete ===
API_PORT=8000

# === Autenticazione ===
# Token per proteggere l'endpoint API vLLM
VLLM_TOKEN=your-secret-token-here
# Token HuggingFace (necessario solo per modelli gated come dots.ocr-1.5)
# HUGGING_FACE_HUB_TOKEN=hf_your_token_here

# === GPU ===
# Percentuale VRAM da usare (0.0-1.0). Ridurre se si usa desktop con GPU
GPU_MEMORY_UTILIZATION=0.80
# Max model length (ridurre per risparmiare VRAM, es. 2048 per 8GB)
MAX_MODEL_LEN=4096

# === Performance ===
MAX_NUM_SEQS=4
MAX_IMAGES_PER_PROMPT=6
