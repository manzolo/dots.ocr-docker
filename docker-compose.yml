services:
  dots-ocr:
    image: ${VLLM_IMAGE:-vllm/vllm-openai:v0.11.1}

    container_name: dots-ocr-service

    ports:
      - "${API_PORT:-8000}:8000"

    # NVIDIA GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      # Persistent HuggingFace cache
      - huggingface-cache:/root/.cache/huggingface
      # Optional log persistence
      - ocr-logs:/var/log/vllm

    environment:
      # Allow HuggingFace downloads
      - HF_HUB_OFFLINE=0
      # vLLM logging level
      - VLLM_LOGGING_LEVEL=INFO
      # Connection timeout
      - VLLM_HTTP_TIMEOUT=300
      # API authentication token (optional)
      - VLLM_TOKEN=${VLLM_TOKEN:-your-secret-token-here}
      # HuggingFace token for gated models (optional)
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
      # CUDA memory: avoid fragmentation
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

    # vLLM command for dots.ocr
    command: >
      --model ${OCR_MODEL:-rednote-hilab/dots.ocr}
      --dtype auto
      --gpu-memory-utilization ${GPU_MEMORY_UTILIZATION:-0.90}
      --max-model-len ${MAX_MODEL_LEN:-8192}
      --max-num-seqs ${MAX_NUM_SEQS:-4}
      --max-num-batched-tokens ${MAX_NUM_BATCHED_TOKENS:-8192}
      --enable-prefix-caching
      --enable-chunked-prefill
      --trust-remote-code
      --served-model-name dots-ocr
      --chat-template-content-format string
      --disable-log-requests
      --limit-mm-per-prompt '{"image": ${MAX_IMAGES_PER_PROMPT:-6}}'
      ${VLLM_EXTRA_ARGS:-}

    # Healthcheck
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    restart: unless-stopped

    # Increased shared memory for GPU workloads
    shm_size: '8gb'

  # CPU-only version (start with: docker compose --profile cpu up -d)
  # Build the image first: ./dots-ocr-manager.sh build-cpu
  dots-ocr-cpu:
    image: ${VLLM_CPU_IMAGE:-dots-ocr-cpu:v0.11.1}

    container_name: dots-ocr-cpu-service
    profiles:
      - cpu

    ports:
      - "${API_PORT:-8000}:8000"

    volumes:
      - huggingface-cache:/root/.cache/huggingface
      - ocr-logs:/var/log/vllm

    environment:
      - HF_HUB_OFFLINE=0
      - VLLM_LOGGING_LEVEL=INFO
      - VLLM_HTTP_TIMEOUT=600
      - VLLM_TOKEN=${VLLM_TOKEN:-your-secret-token-here}
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
      - VLLM_TARGET_DEVICE=cpu

    command: >
      --model ${OCR_MODEL:-rednote-hilab/dots.ocr}
      --dtype float32
      --max-model-len ${MAX_MODEL_LEN:-4096}
      --max-num-seqs 1
      --trust-remote-code
      --served-model-name dots-ocr
      --chat-template-content-format string
      --disable-log-requests
      --limit-mm-per-prompt '{"image": ${MAX_IMAGES_PER_PROMPT:-6}}'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 300s

    restart: unless-stopped
    shm_size: '8gb'

volumes:
  huggingface-cache:
    driver: local
  ocr-logs:
    driver: local
